{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383218, 4415, 12565)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = pd.read_csv(\"recommend-output-all-repo-top-500.csv\")\n",
    "\n",
    "to_lib2cnt = {to_lib: len(rows) for to_lib, rows in rec.groupby(by=\"toLib\")}\n",
    "from_lib2cnt = {from_lib: len(rows) for from_lib, rows in rec.groupby(by=\"fromLib\")}\n",
    "rec[\"confTeyton\"] = (rec[\"ruleCountSameCommit\"] / np.maximum(\n",
    "    rec[\"toLib\"].apply(lambda x: to_lib2cnt[x]),\n",
    "    rec[\"fromLib\"].apply(lambda x: from_lib2cnt[x])\n",
    ")).fillna(0)\n",
    "\n",
    "migrations = pd.read_excel(\"manual/extended-migrations-annotated.xlsx\")\n",
    "rules = set(zip(migrations[\"fromLib\"], migrations[\"toLib\"]))\n",
    "len(rec), len(rules), len(migrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4273, 611)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migrations_true = migrations[migrations[\"isTrue\"]]\n",
    "rules_confirmed = set(zip(migrations_true[\"fromLib\"], migrations_true[\"toLib\"]))\n",
    "len(migrations_true), len(rules_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 1313)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(migrations_true[\"repoName\"])), len(set(migrations[\"repoName\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(migrations_true[\"startCommit\"]) | set(migrations_true[\"endCommit\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(migrations_true[\"fromLib\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2617"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = rec[rec[\"fromLib\"].isin(migrations_true[\"fromLib\"])]\n",
    "# rec = rec[rec[\"toLib\"].apply(lambda x: \"infinispan\" not in x)]\n",
    "rec_filtered = rec[rec[[\"fromLib\",\"toLib\"]].apply(lambda x: (x[0], x[1]) in rules, axis=1)].copy()\n",
    "len(rec_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(method, rules, possible_rules, confirmed_rules):\n",
    "    top_k = 20\n",
    "    top_rules = [list() for x in range(0, top_k)]\n",
    "    ndcg_possible_at_k = [list() for x in range(0, top_k)]\n",
    "    ndcg_confirmed_at_k = [list() for x in range(0, top_k)]\n",
    "    from_lib_set = set(x for x, y in confirmed_rules)\n",
    "    reciprocal_ranks_confirmed = {}\n",
    "    reciprocal_ranks_possible = {}\n",
    "    for from_lib, candidates in rules.groupby(by=\"fromLib\"):\n",
    "        if from_lib not in from_lib_set:\n",
    "            continue\n",
    "        this_rules = [(from_lib, to_lib) for to_lib in candidates[\"toLib\"]]\n",
    "        this_possible_rules = [(from_lib, to_lib) for from_lib, to_lib in this_rules if (from_lib, to_lib) in possible_rules]\n",
    "        this_confirmed_rules = [(from_lib, to_lib) for from_lib, to_lib in this_rules if (from_lib, to_lib) in confirmed_rules]\n",
    "        last_k, last_ndcg = 0, 0\n",
    "        for k, (from_lib, to_lib) in enumerate(this_rules):\n",
    "            if k >= top_k:\n",
    "                continue\n",
    "            last_k = k\n",
    "            top_rules[k].append((from_lib, to_lib))\n",
    "            if (from_lib, to_lib) in possible_rules and from_lib not in reciprocal_ranks_possible:\n",
    "                reciprocal_ranks_possible[from_lib] = 1 / (k + 1)\n",
    "            if (from_lib, to_lib) in confirmed_rules and from_lib not in reciprocal_ranks_confirmed:\n",
    "                reciprocal_ranks_confirmed[from_lib] = 1 / (k + 1)\n",
    "            dcg_p = sum(int((from_lib, to_lib) in possible_rules) / np.log2(i+2) for i, (from_lib, to_lib) in enumerate(this_rules[0:k+1]))\n",
    "            idcg_p = sum(1 / np.log2(i+2) for i in range(0, min(k + 1, len(this_possible_rules))))\n",
    "            if idcg_p == 0:\n",
    "                ndcg_possible_at_k[k].append(0)\n",
    "            else:\n",
    "                ndcg_possible_at_k[k].append(dcg_p / idcg_p)\n",
    "            dcg_c = sum(int((from_lib, to_lib) in confirmed_rules) / np.log2(i+2) for i, (from_lib, to_lib) in enumerate(this_rules[0:k+1]))\n",
    "            idcg_c = sum(1 / np.log2(i+2) for i in range(0, min(k + 1, len(this_confirmed_rules))))\n",
    "            if idcg_c == 0:\n",
    "                ndcg_confirmed_at_k[k].append(0)\n",
    "                last_ndcg = 0\n",
    "            else:\n",
    "                ndcg_confirmed_at_k[k].append(dcg_c / idcg_c)\n",
    "                last_ndcg = dcg_c / idcg_c\n",
    "        for k in range(last_k + 1, top_k):\n",
    "            ndcg_confirmed_at_k[k].append(last_ndcg)\n",
    "        if from_lib not in reciprocal_ranks_possible:\n",
    "            reciprocal_ranks_possible[from_lib] = 0\n",
    "        if from_lib not in reciprocal_ranks_confirmed:\n",
    "            reciprocal_ranks_confirmed[from_lib] = 0\n",
    "            \n",
    "    for k in range(1, top_k):\n",
    "        top_rules[k] += top_rules[k - 1] \n",
    "    result = {\n",
    "        \"Name\": method,\n",
    "        \"FromLibCount\": len(from_lib_set & set(rules[\"fromLib\"])),\n",
    "        \"MRR-C\": np.mean(list(reciprocal_ranks_confirmed.values())),\n",
    "        \"MRR-P\": np.mean(list(reciprocal_ranks_possible.values())),\n",
    "        \"Precision-C@k\": [],\n",
    "        \"Precision-P@k\": [],\n",
    "        \"Recall-C@k\": [],\n",
    "        \"Recall-P@k\": [],\n",
    "        \"NDCG-C@k\": [],\n",
    "        \"NDCG-P@k\": [],\n",
    "    }\n",
    "    for k in range(0, top_k):\n",
    "        precision = len([x for x in top_rules[k] if x in confirmed_rules]) / len(top_rules[k])\n",
    "        recall = len([x for x in top_rules[k] if x in confirmed_rules]) / len(confirmed_rules)\n",
    "        precision_possible = len([x for x in top_rules[k] if x in possible_rules]) / len(top_rules[k])\n",
    "        recall_possible = len([x for x in top_rules[k] if x in possible_rules]) / len(possible_rules)\n",
    "        result[\"Precision-C@k\"].append(precision)\n",
    "        result[\"Precision-P@k\"].append(precision_possible)\n",
    "        result[\"Recall-C@k\"].append(recall)\n",
    "        result[\"Recall-P@k\"].append(recall_possible)\n",
    "        if len(ndcg_confirmed_at_k[k]) > 0:\n",
    "            result[\"NDCG-C@k\"].append(np.mean(ndcg_confirmed_at_k[k]))\n",
    "        else:\n",
    "            result[\"NDCG-C@k\"].append(0)\n",
    "        if len(ndcg_possible_at_k[k]) > 0:\n",
    "            result[\"NDCG-P@k\"].append(np.mean(ndcg_possible_at_k[k]))\n",
    "        else:\n",
    "            result[\"NDCG-P@k\"].append(0)\n",
    "    return result\n",
    "def print_evaluation_result(result):\n",
    "    print(\"Result of {} on {} Library Queries:\".format(result[\"Name\"], result[\"FromLibCount\"]))\n",
    "    print(\"MRR-C/P = {}/{}\".format(result[\"MRR-C\"], result[\"MRR-P\"]))\n",
    "    for k in range(0, len(result[\"Precision-C@k\"])):\n",
    "        if k + 1 > 10 and (k + 1) % 10 != 0:\n",
    "            continue\n",
    "        print(\"Top {:3}: Precision = {:0.4f}, Recall = {:0.4f}, NDCG = {:0.4f}\"\n",
    "              .format(k + 1, result[\"Precision-C@k\"][k], result[\"Recall-C@k\"][k], result[\"NDCG-C@k\"][k]))\n",
    "def print_one_line_evaluation_result(result):\n",
    "    print(\"{:30}: Precision@1 = {:0.4f}, MRR = {:0.4f}, Recall@5 = {:0.4f}, Recall@10 = {:0.4f}, \"\n",
    "         \"Recall@20 = {:0.4f}, NDCG@10 = {:0.4f}\".format(\n",
    "             result[\"Name\"],\n",
    "             result[\"Precision-C@k\"][0],\n",
    "             result[\"MRR-C\"],\n",
    "             result[\"Recall-C@k\"][4],\n",
    "             result[\"Recall-C@k\"][9],\n",
    "             result[\"Recall-C@k\"][19],\n",
    "             result[\"NDCG-C@k\"][9]\n",
    "         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Our Method on 230 Library Queries:\n",
      "MRR-C/P = 0.7880833013249893/0.7880833013249893\n",
      "Top   1: Precision-C/P = 0.6783/0.6783, Recall-C/P = 0.2553/0.2553, NDCG-C/P = 0.6783/0.6783\n",
      "Top   2: Precision-C/P = 0.5413/0.5413, Recall-C/P = 0.4075/0.4075, NDCG-C/P = 0.6856/0.6856\n",
      "Top   3: Precision-C/P = 0.4507/0.4507, Recall-C/P = 0.5090/0.5090, NDCG-C/P = 0.6962/0.6962\n",
      "Top   4: Precision-C/P = 0.3891/0.3891, Recall-C/P = 0.5859/0.5859, NDCG-C/P = 0.7133/0.7133\n",
      "Top   5: Precision-C/P = 0.3391/0.3391, Recall-C/P = 0.6383/0.6383, NDCG-C/P = 0.7235/0.7235\n",
      "Top   6: Precision-C/P = 0.3080/0.3080, Recall-C/P = 0.6956/0.6956, NDCG-C/P = 0.7372/0.7372\n",
      "Top   7: Precision-C/P = 0.2789/0.2789, Recall-C/P = 0.7349/0.7349, NDCG-C/P = 0.7467/0.7467\n",
      "Top   8: Precision-C/P = 0.2565/0.2565, Recall-C/P = 0.7725/0.7725, NDCG-C/P = 0.7583/0.7583\n",
      "Top   9: Precision-C/P = 0.2382/0.2382, Recall-C/P = 0.8069/0.8069, NDCG-C/P = 0.7675/0.7675\n",
      "Top  10: Precision-C/P = 0.2191/0.2191, Recall-C/P = 0.8249/0.8249, NDCG-C/P = 0.7702/0.7702\n",
      "Top  20: Precision-C/P = 0.1326/0.1326, Recall-C/P = 0.9984/0.9984, NDCG-C/P = 0.8048/0.8048\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\"Our Method\", rec, rules_confirmed, rules_confirmed)\n",
    "print_evaluation_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Our Method on 230 Library Queries:\n",
      "MRR-C/P = 0.8426552795031056/0.8426552795031056\n",
      "Top   1: Precision-C/P = 0.7565/0.7565, Recall-C/P = 0.2848/0.2848, NDCG-C/P = 0.7565/0.7565\n",
      "Top   2: Precision-C/P = 0.5996/0.5996, Recall-C/P = 0.4435/0.4435, NDCG-C/P = 0.7516/0.7427\n",
      "Top   3: Precision-C/P = 0.5052/0.5052, Recall-C/P = 0.5548/0.5548, NDCG-C/P = 0.7628/0.7526\n",
      "Top   4: Precision-C/P = 0.4381/0.4381, Recall-C/P = 0.6318/0.6318, NDCG-C/P = 0.7748/0.7604\n",
      "Top   5: Precision-C/P = 0.3942/0.3942, Recall-C/P = 0.6956/0.6956, NDCG-C/P = 0.7875/0.7642\n",
      "Top   6: Precision-C/P = 0.3610/0.3610, Recall-C/P = 0.7480/0.7480, NDCG-C/P = 0.8000/0.7769\n",
      "Top   7: Precision-C/P = 0.3338/0.3338, Recall-C/P = 0.7856/0.7856, NDCG-C/P = 0.8085/0.7773\n",
      "Top   8: Precision-C/P = 0.3132/0.3132, Recall-C/P = 0.8216/0.8216, NDCG-C/P = 0.8170/0.7846\n",
      "Top   9: Precision-C/P = 0.2978/0.2978, Recall-C/P = 0.8543/0.8543, NDCG-C/P = 0.8251/0.7962\n",
      "Top  10: Precision-C/P = 0.2831/0.2831, Recall-C/P = 0.8756/0.8756, NDCG-C/P = 0.8284/0.7983\n",
      "Top  20: Precision-C/P = 0.2331/0.2331, Recall-C/P = 0.9984/0.9984, NDCG-C/P = 0.8498/0.7461\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\"Our Method\", rec_filtered, rules_confirmed, rules_confirmed)\n",
    "print_evaluation_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teyton et al. 2013            : Precision@1 = 0.6000, MRR = 0.6997, Recall@5 = 0.5254, Recall@10 = 0.6759, Recall@20 = 0.8527, NDCG@10 = 0.6446\n",
      "Teyton et al. 2013'           : Precision@1 = 0.6035, MRR = 0.7008, Recall@5 = 0.5188, Recall@10 = 0.6661, Recall@20 = 0.8020, NDCG@10 = 0.6693\n",
      "Teyton et al. 2013''          : Precision@1 = 0.8148, MRR = 0.8410, Recall@5 = 0.2209, Recall@10 = 0.2226, Recall@20 = 0.2226, NDCG@10 = 0.8482\n",
      "Alrubaye et al. 2019          : Precision@1 = 0.9143, MRR = 0.9143, Recall@5 = 0.0540, Recall@10 = 0.0540, Recall@20 = 0.0540, NDCG@10 = 0.9143\n",
      "Our Approach                  : Precision@1 = 0.6826, MRR = 0.7899, Recall@5 = 0.6514, Recall@10 = 0.8314, Recall@20 = 0.9902, NDCG@10 = 0.7760\n"
     ]
    }
   ],
   "source": [
    "def teyton_2013(rules, t):\n",
    "    return rules[rules[\"confTeyton\"]>=t].sample(frac=1).sort_values(by=[\"fromLib\", \"confTeyton\"], ascending=[True, False])\n",
    "def method(rules, a, b, c, d):\n",
    "    rules[\"confidence\"] = (\n",
    "        rules[\"ruleFreqSameCommit\"] ** a\n",
    "        * np.maximum(0.1, rules[\"apiSupport\"]) ** b\n",
    "        * rules[\"commitDistance\"] ** c\n",
    "        * np.log2(rules[\"possibleCommitCount\"] + 1) ** d\n",
    "    )\n",
    "    return rules.sample(frac=1).sort_values(by=[\"fromLib\", \"confidence\"], ascending=[True, False])\n",
    "def our_method(rules):\n",
    "    rules[\"confidence\"] = (\n",
    "        rules[\"ruleFreqSameCommit\"]\n",
    "        * np.maximum(0.1, rules[\"apiSupport\"])\n",
    "        * rules[\"commitDistance\"]\n",
    "        * np.log2(rules[\"possibleCommitCount\"] + 1)\n",
    "    )\n",
    "    return rules.sample(frac=1).sort_values(by=[\"fromLib\", \"confidence\"], ascending=[True, False])\n",
    "def parallel_worker(name, func, params):\n",
    "    return evaluate(name, func(rec, *params), rules_confirmed, rules_confirmed)\n",
    "methods = [\n",
    "    (\"Teyton et al. 2013\", teyton_2013, (0,)),\n",
    "    (\"Teyton et al. 2013'\", teyton_2013, (0.002,)),\n",
    "    (\"Teyton et al. 2013''\", teyton_2013, (0.015,)),\n",
    "    (\"Alrubaye et al. 2019\", alrubaye_2019, ()),\n",
    "    (\"Our Approach\", our_method, ())\n",
    "]\n",
    "pool = multiprocessing.Pool(12)\n",
    "results = pool.starmap(parallel_worker, methods)\n",
    "pool.close()\n",
    "pool.join()\n",
    "for result in results:\n",
    "    print_one_line_evaluation_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Alrubaye et al. 2019 on 35 Library Queries:\n",
      "MRR-C/P = 0.9142857142857143/0.9142857142857143\n",
      "Top   1: Precision-C/P = 0.9143/0.9143, Recall-C/P = 0.0524/0.0524, NDCG-C/P = 0.9143/0.9143\n",
      "Top   2: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.5000\n",
      "Top   3: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   4: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   5: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   6: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   7: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   8: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top   9: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top  10: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n",
      "Top  20: Precision-C/P = 0.8919/0.8919, Recall-C/P = 0.0540/0.0540, NDCG-C/P = 0.9143/0.0000\n"
     ]
    }
   ],
   "source": [
    "def alrubaye_2019(rules):\n",
    "    return rules[\n",
    "        (rules[\"methodChangeCount\"] > 0) & (rules[\"ruleFreqSameCommit\"] >= 0.6)\n",
    "    ].sample(frac=1).sort_values(by=[\"fromLib\", \"ruleFreqSameCommit\"], ascending=[True, False])\n",
    "result = evaluate(\"Alrubaye et al. 2019\", alrubaye_2019(rec), rules_confirmed, rules_confirmed)\n",
    "print_evaluation_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
